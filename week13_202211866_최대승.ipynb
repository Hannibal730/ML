{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 202211866 최대승\n",
        "## 13주차 기계학습 과제 수행에 앞선 학습데이터 준비 과정입니다.\n",
        "\n",
        "* NIA AI-Hub에서 다운로드 받은 뷰티 카테고리의 json데이터를 활용하기로 함\n",
        "* 코랩의 data 폴더에 json파일을 130개를 저장함\n",
        "* 각 json파일에서 댓글 문장 (content)만 전부 추출함\n",
        "* 댓글 문장을 추출할 때마다 전처리를 거침\n",
        "* 전처리 과정\n",
        "  1. 모든 공백을 &lt;SP&gt;로 변환\n",
        "  2. 음절 단위마다 띄어쓰기 추가\n",
        "  3. 띄어쓰기 추가로 인해 변형된 < S P >를 다시 &lt;SP&gt; 로 복원\n",
        "* 댓글 문장 두 개를 질문과 응답으로 짝을 지어서 1만개의 짝을 만들어야 해서, 댓글 문장이 2만 개 필요했음.\n",
        "* 댓글 문장을 총 2만 개 추출할 때까지 추출함.\n",
        "* 2만 개의 전처리된 문장을 확보하면, 두 개씩 짝 지음\n",
        "* 짝 지어진 문장 중 첫번째 문장 뒤에 \\t 추가\n",
        "* 짝 지어진 문장 중 두번째 문장 뒤에 &lt;/S&gt; 추가\n",
        "* 짝 지어진 문장들을 txt파일에 저장하고, 훈련데이터로 사용\n",
        "* vocab데이터는 실습과정에서 썼던 데이터를 그대로 사용\n",
        "\n",
        "\n",
        "## 제가 사용한 130개의 json데이터, 이를 사용하여 준비한 학습데이터(1만개의 질문-응답 쌍)는 과제 제출할 때 같이 제출하겠습니다."
      ],
      "metadata": {
        "id": "XNEARzNmzDYn"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j65i49dU8Cjs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36706940-66a9-4929-f242-7bfa37c7cd1b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/gdrive\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "DwRdXJy5zV5j"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "# 전처리 과정\n",
        "def ask_spaces(texts):\n",
        "    processed_texts = []\n",
        "    for text in texts:\n",
        "        # 공백을 <SP>로 변환\n",
        "        text = text.replace(\" \", \"<SP>\")\n",
        "        # 음절 단위로 분리\n",
        "        syllables = \" \".join(text)  # 한글자씩 분리\n",
        "        syllables = syllables.replace(\"< S P >\", \"<SP>\")  # \"< S P >\"를 \"<SP>\"로 복원\n",
        "        processed_texts.append(syllables)\n",
        "    return processed_texts\n",
        "\n",
        "\n",
        "# 설정\n",
        "folder_path = \"/gdrive/My Drive/ML/13w/data/\"  # JSON 파일들이 들어 있는 폴더 경로\n",
        "output_file = \"/gdrive/My Drive/ML/13w/train.txt\"  # 결과 파일 경로\n",
        "target_sentence_count = 20000  # 목표 문장 개수 (질문 1만개, 대답1만개)\n",
        "\n",
        "# 문장을 저장할 리스트\n",
        "all_processed_texts = []\n",
        "\n",
        "# 폴더 내 JSON 파일 순회\n",
        "for file_name in os.listdir(folder_path):\n",
        "    # JSON 파일만 처리\n",
        "    if file_name.endswith(\".json\"):\n",
        "        file_path = os.path.join(folder_path, file_name)\n",
        "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "            data = json.load(file)\n",
        "\n",
        "        # content 필드에서 텍스트 추출\n",
        "        texts = [item[\"content\"] for item in data[\"SJML\"][\"text\"]]\n",
        "\n",
        "        # 전처리 수행\n",
        "        processed_texts = ask_spaces(texts)\n",
        "        all_processed_texts.extend(processed_texts)\n",
        "\n",
        "    # 목표 문장 개수에 도달하면 중단\n",
        "    if len(all_processed_texts) >= target_sentence_count:\n",
        "        break\n",
        "\n",
        "# 최종 문장 리스트를 목표 개수로 자르기\n",
        "all_processed_texts = all_processed_texts[:target_sentence_count]\n",
        "\n",
        "# 결과를 두 개씩 짝짓기\n",
        "paired_texts = []\n",
        "for i in range(0, len(all_processed_texts) - 1, 2):  # 두 개씩 묶음\n",
        "    first = all_processed_texts[i]+\"\\t\"\n",
        "    second = all_processed_texts[i+1]+\" </S>\"\n",
        "    paired_texts.append(f\"{first}{second}\")\n",
        "\n",
        "# 결과를 txt 파일로 저장\n",
        "with open(output_file, \"w\", encoding=\"utf-8\") as out_file:\n",
        "    out_file.write(\"\\n\".join(paired_texts))\n",
        "\n",
        "print(f\"전처리 완료: 총 {len(paired_texts)}개의 쌍이 저장되었습니다.\")\n"
      ],
      "metadata": {
        "id": "NLeJgONRMPh3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49f108ea-a7d9-4947-a31f-2dfc065cce56"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전처리 완료: 총 9182개의 쌍이 저장되었습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zVeC5Mf8C-S"
      },
      "source": [
        "from torch.utils.data import (DataLoader, TensorDataset)\n",
        "from torch import nn\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "\n",
        "class TransformerChat(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "\n",
        "        # 전체 단어(음절) 개수\n",
        "        self.vocab_size = config[\"vocab_size\"]\n",
        "\n",
        "        # 단어(음절) 벡터 크기\n",
        "        self.embedding_size = config['embedding_size']\n",
        "\n",
        "        # Transformer의 Attention Head 개수\n",
        "        self.num_heads = config['num_heads']\n",
        "\n",
        "        # Transformer Encoder의 Layer 수\n",
        "        self.num_encoder_layers = config['num_encoder_layers']\n",
        "\n",
        "        # Transformer Decoder의 Layer 수\n",
        "        self.num_decoder_layers = config['num_decoder_layers']\n",
        "\n",
        "        # 입력 Sequence의 최대 길이\n",
        "        self.max_length = config['max_length']\n",
        "\n",
        "        # Transformer 내부 FNN 크기\n",
        "        self.hidden_size = config['hidden_size']\n",
        "\n",
        "        # Token Embedding Matrix 선언\n",
        "        self.embeddings = nn.Embedding(self.vocab_size, self.embedding_size)\n",
        "\n",
        "        # Transformer Encoder-Decoder 설계(선언)\n",
        "        self.transformer = nn.Transformer(d_model=self.embedding_size, nhead=self.num_heads, num_encoder_layers=self.num_encoder_layers,\n",
        "                                          num_decoder_layers=self.num_decoder_layers, dim_feedforward=self.hidden_size)\n",
        "\n",
        "        # 입력 길이 L에 대한 (L X L) mask 생성: 이전 토큰들의 정보만을 반영하기 위한 mask\n",
        "        #       [[1, -inf, -inf, -inf],\n",
        "        #        [1,    1, -inf, -inf],\n",
        "        #               ......\n",
        "        #        [1,    1,    1,    1]]\n",
        "        self.mask = self.transformer.generate_square_subsequent_mask(self.max_length).cuda()\n",
        "\n",
        "        # 출력층 선언\n",
        "\n",
        "        # 전체 단어 분포로 변환하기 위한 linear\n",
        "        # 이곳을 채우세요.\n",
        "        self.projection_layer = nn.Linear(self.embedding_size, self.vocab_size)\n",
        "\n",
        "    def forward(self, enc_inputs, dec_inputs):\n",
        "\n",
        "        # enc_inputs: [batch, seq_len], dec_inputs: [batch, seq_len]\n",
        "        # enc_input_features: [batch, seq_len, emb_size] -> [seq_len, batch, emb_size]\n",
        "        # 이곳을 채우세요.\n",
        "        enc_input_features = self.embeddings(enc_inputs).transpose(0, 1)\n",
        "\n",
        "        # dec_input_features: [batch, seq_len, emb_size] -> [seq_len, batch, emb_size]\n",
        "        # 이곳을 채우세요.\n",
        "        dec_input_features = self.embeddings(dec_inputs).transpose(0, 1)\n",
        "\n",
        "        # dec_output_features: [seq_len, batch, emb_size]\n",
        "        dec_output_features = self.transformer(src=enc_input_features, tgt=dec_input_features, src_mask = self.mask, tgt_mask = self.mask)\n",
        "\n",
        "        # hypothesis : [seq_len, batch, vocab_size]\n",
        "        hypothesis = self.projection_layer(dec_output_features)\n",
        "\n",
        "        return hypothesis"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmYHzEcU8nRp"
      },
      "source": [
        "# 어휘사전(vocabulary) 생성 함수\n",
        "def load_vocab(file_dir):\n",
        "\n",
        "  with open(file_dir,'r',encoding='utf8') as vocab_file:\n",
        "      char2idx = {}\n",
        "      idx2char = {}\n",
        "      index = 0\n",
        "      for char in vocab_file:\n",
        "          char = char.strip()\n",
        "          char2idx[char] = index\n",
        "          idx2char[index] = char\n",
        "          index+=1\n",
        "\n",
        "  return char2idx, idx2char\n",
        "\n",
        "# 문자 입력열을 인덱스로 변환하는 함수\n",
        "def convert_data2feature(config, input_sequence, char2idx, decoder_input=False):\n",
        "\n",
        "    # 고정 길이 벡터 생성\n",
        "    input_features = np.zeros(config[\"max_length\"], dtype=np.int64)\n",
        "\n",
        "    if decoder_input:\n",
        "        # Decoder Input은 Target Sequence에서 Right Shift\n",
        "        # Target Sequence: [\"안\", \"녕\", \"하\", \"세\", \"요\", \"</S>\"]\n",
        "        # Decoder Input Sequence: [\"<S>\", \"안\", \"녕\", \"하\", \"세\", \"요\"]\n",
        "        input_sequence = \" \".join([\"<S>\"] + input_sequence.split())\n",
        "\n",
        "    # 입력 시퀀스 토큰 분리 및 길이 제한\n",
        "    tokens = input_sequence.split()[:config[\"max_length\"]]\n",
        "\n",
        "    # 토큰을 인덱스로 변환하여 고정 길이 벡터에 저장\n",
        "    for idx, token in enumerate(tokens):\n",
        "        if token in char2idx:\n",
        "            input_features[idx] = char2idx[token]\n",
        "        else:\n",
        "            input_features[idx] = char2idx.get('<UNK>', 0)  # '<UNK>'가 없으면 기본값 0\n",
        "\n",
        "    return input_features\n",
        "\n",
        "\n",
        "# 데이터 읽기 함수\n",
        "def load_dataset(config):\n",
        "\n",
        "    # 어휘사전 읽어오기\n",
        "    char2idx, idx2char = load_vocab(config['vocab_file'])\n",
        "\n",
        "    file_dir = config['train_file']\n",
        "    data_file = open(file_dir,'r',encoding='utf8').readlines()\n",
        "\n",
        "    # 데이터를 저장하기 위한 리스트 생성\n",
        "    enc_inputs, dec_inputs, dec_outputs = [], [], []\n",
        "\n",
        "    for line in tqdm(data_file):\n",
        "\n",
        "        line = line.strip().split('\\t')\n",
        "\n",
        "        input_sequence = line[0]\n",
        "        output_sequence = line[1]\n",
        "\n",
        "        enc_inputs.append(convert_data2feature(config, input_sequence, char2idx))\n",
        "        dec_inputs.append(convert_data2feature(config, output_sequence, char2idx, True))\n",
        "        dec_outputs.append(convert_data2feature(config, output_sequence, char2idx))\n",
        "\n",
        "    # 전체 데이터를 저장하고 있는 리스트를 텐서 형태로 변환\n",
        "    enc_inputs = torch.tensor(enc_inputs, dtype=torch.long)\n",
        "    dec_inputs = torch.tensor(dec_inputs, dtype=torch.long)\n",
        "    dec_outputs = torch.tensor(dec_outputs, dtype=torch.long)\n",
        "\n",
        "    return enc_inputs, dec_inputs, dec_outputs, char2idx, idx2char"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ow01KJjz-416"
      },
      "source": [
        "def train(config):\n",
        "\n",
        "    # Transformer Seq2Seq 모델 객체 생성\n",
        "    model = TransformerChat(config).cuda()\n",
        "\n",
        "    # 데이터 읽기\n",
        "    enc_inputs, dec_inputs, dec_outputs, word2idx, idx2word = load_dataset(config)\n",
        "\n",
        "    # TensorDataset/DataLoader를 통해 배치(batch) 단위로 데이터를 나누고 셔플(shuffle)\n",
        "    train_features = TensorDataset(enc_inputs, dec_inputs, dec_outputs)\n",
        "    train_dataloader = DataLoader(train_features, shuffle=True, batch_size=config[\"batch_size\"])\n",
        "\n",
        "    # 크로스엔트로피 손실 함수\n",
        "    loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "    # 옵티마이저 함수 지정\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=config[\"learn_rate\"])\n",
        "\n",
        "    for epoch in range(config[\"epoch\"] + 1):\n",
        "\n",
        "        for (step, batch) in enumerate(train_dataloader):\n",
        "\n",
        "            # 학습 모드 셋팅\n",
        "            model.train()\n",
        "\n",
        "            # batch = (enc_inputs[step], dec_inputs[step], dec_outputs)*batch_size\n",
        "            # .cuda()를 통해 메모리에 업로드\n",
        "            batch = tuple(t.cuda() for t in batch)\n",
        "\n",
        "            # 역전파 변화도 초기화\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            enc_inputs, dec_inputs, dec_outputs = batch\n",
        "\n",
        "            # hypothesis: [seq_len, batch, vocab_size] -> [seq_len*batch, vocab_size]\n",
        "            # 이곳을 채우세요.\n",
        "            hypothesis = model(enc_inputs, dec_inputs).view(-1, config[\"vocab_size\"])\n",
        "\n",
        "            # labels: [batch, seq_len] -> [seq_len, batch] -> [seq_len(max_length)*batch]\n",
        "            labels = dec_outputs.transpose(0, 1)\n",
        "            labels = labels.reshape(config[\"max_length\"]*dec_inputs.size(0))\n",
        "\n",
        "            # 비용 계산 및 역전파 수행: cross_entopy 내부에서 labels를 원핫벡터로 변환 (골드레이블은 항상 1차원으로 입력)\n",
        "            loss = loss_func(hypothesis, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # 10 배치마다 중간 결과 출력\n",
        "            if (step+1)% 10 == 0:\n",
        "                print(\"Current Step : {0:d} / {1:d}\\tCurrent Loss : {2:f}\".format(step+1, int(len(enc_inputs) / config['batch_size']), loss.item()))\n",
        "                # 생성 문장을 확인하기 위한 함수 호출\n",
        "                # do_test(config, model, word2idx, idx2word)\n",
        "\n",
        "        # 에폭마다 가중치 저장\n",
        "        torch.save(model.state_dict(), os.path.join(config[\"output_dir\"], \"epoch_{0:d}.pt\".format(epoch)))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJ-bIKnw-1D8"
      },
      "source": [
        "# 텐서를 리스트로 변환하는 함수\n",
        "def tensor2list(input_tensor):\n",
        "    return input_tensor.cpu().detach().numpy().tolist()\n",
        "\n",
        "def do_test(config, model, word2idx, idx2word, input_sequence=\"오늘 약속있으세요?\"):\n",
        "\n",
        "    # 평가 모드 셋팅\n",
        "    model.eval()\n",
        "\n",
        "    # 입력된 문자열의 음절을 공백 단위 토큰으로 변환. 공백은 <SP>로 변환: \"오늘 약속\" -> \"오 늘 <SP> 약 속\"\n",
        "    input_sequence = \" \".join([e if e != \" \" else \"<SP>\" for e in input_sequence])\n",
        "\n",
        "    # 텐서 변환: [1, seq_len]\n",
        "    enc_inputs = torch.tensor([convert_data2feature(config, input_sequence, word2idx)], dtype=torch.long).cuda()\n",
        "\n",
        "    # input_ids : [1, seq_len] -> 첫번째 디코더 입력 \"<S>\" 만들기\n",
        "    dec_inputs = torch.tensor([convert_data2feature(config, \"\", word2idx, True)], dtype=torch.long).cuda()\n",
        "\n",
        "    # 시스템 응답 문자열 초기화\n",
        "    response = ''\n",
        "\n",
        "    # 최대 입력 길이 만큼 Decoding Loop\n",
        "    for decoding_step in range(config['max_length']-1):\n",
        "\n",
        "        # dec_outputs: [vocab_size]\n",
        "        dec_outputs = model(enc_inputs, dec_inputs)[decoding_step, 0, :]\n",
        "        # 가장 큰 출력을 갖는 인덱스 얻어오기\n",
        "        dec_output_idx = np.argmax(tensor2list(dec_outputs))\n",
        "\n",
        "        # 생성된 토큰은 dec_inputs에 추가 (첫번째 차원은 배치)\n",
        "        dec_inputs[0][decoding_step+1] = dec_output_idx\n",
        "\n",
        "        # </S> 심볼 생성 시, Decoding 종료\n",
        "        if idx2word[dec_output_idx] == \"</S>\":\n",
        "            break\n",
        "\n",
        "        # 생성 토큰 추가\n",
        "        response += idx2word[dec_output_idx]\n",
        "\n",
        "    # <SP>를 공백으로 변환한 후 응답 문자열 출력\n",
        "    print(response.replace(\"<SP>\", \" \"))\n",
        "\n",
        "def test(config):\n",
        "\n",
        "    # 어휘사전 읽어오기\n",
        "    word2idx, idx2word = load_vocab(config['vocab_file'])\n",
        "\n",
        "    # Transformer Seq2Seq 모델 객체 생성\n",
        "    model = TransformerChat(config).cuda()\n",
        "\n",
        "    # 학습한 모델 파일로부터 가중치 불러옴\n",
        "    model.load_state_dict(torch.load(os.path.join(config[\"output_dir\"], config[\"trained_model_name\"])))\n",
        "\n",
        "    while(True):\n",
        "        input_sequence = input(\"문장을 입력하세요. (종료는 exit을 입력하세요.) : \")\n",
        "        if input_sequence == 'exit':\n",
        "            break\n",
        "        do_test(config, model, word2idx, idx2word, input_sequence)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def do_test (config, model, word2idx, idx2word, input_sequence = \"오늘 약속있으세요?\"):\n",
        "  model.eval()\n",
        "  input_sequence = \" \".join([e if e != \" \" else \"<SP>\" for e in input_sequence])\n",
        "  enc_inputs = torch.tensor([convert_data2feature(config, input_sequence, word2idx)], dtype=torch.long).cuda()\n",
        "  dec_inputs = torch.tensor([convert_data2feature(config, \"\", word2idx, True)], dtype=torch.long).cuda()\n",
        "  response = ''\n",
        "  for decoding_step in range(config['max_length']-1):\n",
        "    dec_outputs = model(enc_inputs, dec_inputs)[decoding_step, 0, :]\n",
        "    dec_output_idx = np.argmax(tensor2list(dec_outputs))\n",
        "    dec_inputs[0][decoding_step+1] = dec_output_idx\n",
        "    if idx2word[dec_output_idx] == \"</S>\":\n",
        "      break\n",
        "    response += idx2word[dec_output_idx]\n",
        "\n",
        "  print(response.replace(\"<SP>\", \"\"))\n"
      ],
      "metadata": {
        "id": "TwSkev9_6nlo"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(config):\n",
        "\n",
        "  word2idx, idx2word = load_vocab(config['vocab_file'])\n",
        "  model = TransformerChat(config).cuda()\n",
        "  model.load_state_dict(torch.load(os.path.join(config[\"output_dir\"], config[\"trained_model_name\"])))\n",
        "  while(True):\n",
        "    input_sequence = input(\"문장을 입력하세요. (종료는 exit을 입력하세요.) : \")\n",
        "    if input_sequence == 'exit':\n",
        "      break\n",
        "    do_test (config, model, word2idx, idx2word, input_sequence)"
      ],
      "metadata": {
        "id": "ZAbmDXP76Ce9"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fk1BLZ-VrHe",
        "outputId": "18a2fdd6-37bf-4f28-e0f4-29db1d9492e2"
      },
      "source": [
        "if(__name__==\"__main__\"):\n",
        "\n",
        "    root_dir = \"/gdrive/My Drive/ML/13w/\"\n",
        "    output_dir = os.path.join(root_dir, \"output\")\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "    config = {\"mode\": \"train\",\n",
        "              \"vocab_file\": os.path.join(root_dir, \"vocab.txt\"),\n",
        "              \"train_file\": os.path.join(root_dir, \"train.txt\"),\n",
        "              \"trained_model_name\":\"epoch_{}.pt\".format(10),\n",
        "              \"output_dir\":output_dir,\n",
        "              \"epoch\": 10,\n",
        "              \"learn_rate\":0.00005,\n",
        "              \"num_encoder_layers\": 6,\n",
        "              \"num_decoder_layers\": 6,\n",
        "              \"num_heads\": 4,\n",
        "              \"max_length\": 20,\n",
        "              \"batch_size\": 128,\n",
        "              \"embedding_size\": 256,\n",
        "              \"hidden_size\": 512,\n",
        "              \"vocab_size\": 4427\n",
        "            }\n",
        "\n",
        "    if(config[\"mode\"] == \"train\"):\n",
        "        train(config)\n",
        "    else:\n",
        "        test(config)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n",
            "100%|██████████| 9182/9182 [00:00<00:00, 36312.98it/s]\n",
            "<ipython-input-5-4810e4e636fb>:65: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  enc_inputs = torch.tensor(enc_inputs, dtype=torch.long)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current Step : 10 / 1\tCurrent Loss : 7.229414\n",
            "Current Step : 20 / 1\tCurrent Loss : 6.801976\n",
            "Current Step : 30 / 1\tCurrent Loss : 6.342338\n",
            "Current Step : 40 / 1\tCurrent Loss : 6.204791\n",
            "Current Step : 50 / 1\tCurrent Loss : 5.941228\n",
            "Current Step : 60 / 1\tCurrent Loss : 6.005876\n",
            "Current Step : 70 / 1\tCurrent Loss : 5.576653\n",
            "Current Step : 10 / 1\tCurrent Loss : 5.382502\n",
            "Current Step : 20 / 1\tCurrent Loss : 5.320533\n",
            "Current Step : 30 / 1\tCurrent Loss : 5.165909\n",
            "Current Step : 40 / 1\tCurrent Loss : 5.157838\n",
            "Current Step : 50 / 1\tCurrent Loss : 4.933252\n",
            "Current Step : 60 / 1\tCurrent Loss : 5.015621\n",
            "Current Step : 70 / 1\tCurrent Loss : 4.958889\n",
            "Current Step : 10 / 1\tCurrent Loss : 4.767728\n",
            "Current Step : 20 / 1\tCurrent Loss : 4.498380\n",
            "Current Step : 30 / 1\tCurrent Loss : 4.635081\n",
            "Current Step : 40 / 1\tCurrent Loss : 4.725713\n",
            "Current Step : 50 / 1\tCurrent Loss : 4.634593\n",
            "Current Step : 60 / 1\tCurrent Loss : 4.617172\n",
            "Current Step : 70 / 1\tCurrent Loss : 4.478467\n",
            "Current Step : 10 / 1\tCurrent Loss : 4.396565\n",
            "Current Step : 20 / 1\tCurrent Loss : 4.507817\n",
            "Current Step : 30 / 1\tCurrent Loss : 4.413782\n",
            "Current Step : 40 / 1\tCurrent Loss : 4.472165\n",
            "Current Step : 50 / 1\tCurrent Loss : 4.362165\n",
            "Current Step : 60 / 1\tCurrent Loss : 4.250794\n",
            "Current Step : 70 / 1\tCurrent Loss : 4.286034\n",
            "Current Step : 10 / 1\tCurrent Loss : 4.402075\n",
            "Current Step : 20 / 1\tCurrent Loss : 4.304338\n",
            "Current Step : 30 / 1\tCurrent Loss : 4.229450\n",
            "Current Step : 40 / 1\tCurrent Loss : 4.414494\n",
            "Current Step : 50 / 1\tCurrent Loss : 4.359869\n",
            "Current Step : 60 / 1\tCurrent Loss : 4.444096\n",
            "Current Step : 70 / 1\tCurrent Loss : 3.943357\n",
            "Current Step : 10 / 1\tCurrent Loss : 4.215039\n",
            "Current Step : 20 / 1\tCurrent Loss : 4.217830\n",
            "Current Step : 30 / 1\tCurrent Loss : 3.994779\n",
            "Current Step : 40 / 1\tCurrent Loss : 4.226064\n",
            "Current Step : 50 / 1\tCurrent Loss : 4.095331\n",
            "Current Step : 60 / 1\tCurrent Loss : 4.040978\n",
            "Current Step : 70 / 1\tCurrent Loss : 4.188307\n",
            "Current Step : 10 / 1\tCurrent Loss : 3.954520\n",
            "Current Step : 20 / 1\tCurrent Loss : 3.850032\n",
            "Current Step : 30 / 1\tCurrent Loss : 4.092634\n",
            "Current Step : 40 / 1\tCurrent Loss : 4.160615\n",
            "Current Step : 50 / 1\tCurrent Loss : 3.959431\n",
            "Current Step : 60 / 1\tCurrent Loss : 3.968785\n",
            "Current Step : 70 / 1\tCurrent Loss : 3.842934\n",
            "Current Step : 10 / 1\tCurrent Loss : 3.877738\n",
            "Current Step : 20 / 1\tCurrent Loss : 3.979516\n",
            "Current Step : 30 / 1\tCurrent Loss : 3.827361\n",
            "Current Step : 40 / 1\tCurrent Loss : 3.802739\n",
            "Current Step : 50 / 1\tCurrent Loss : 4.067458\n",
            "Current Step : 60 / 1\tCurrent Loss : 3.934623\n",
            "Current Step : 70 / 1\tCurrent Loss : 3.889881\n",
            "Current Step : 10 / 1\tCurrent Loss : 3.737963\n",
            "Current Step : 20 / 1\tCurrent Loss : 3.736081\n",
            "Current Step : 30 / 1\tCurrent Loss : 3.650480\n",
            "Current Step : 40 / 1\tCurrent Loss : 3.838147\n",
            "Current Step : 50 / 1\tCurrent Loss : 3.686158\n",
            "Current Step : 60 / 1\tCurrent Loss : 4.025894\n",
            "Current Step : 70 / 1\tCurrent Loss : 3.842664\n",
            "Current Step : 10 / 1\tCurrent Loss : 3.745812\n",
            "Current Step : 20 / 1\tCurrent Loss : 3.754425\n",
            "Current Step : 30 / 1\tCurrent Loss : 3.704903\n",
            "Current Step : 40 / 1\tCurrent Loss : 3.820941\n",
            "Current Step : 50 / 1\tCurrent Loss : 3.791558\n",
            "Current Step : 60 / 1\tCurrent Loss : 3.666031\n",
            "Current Step : 70 / 1\tCurrent Loss : 3.757922\n",
            "Current Step : 10 / 1\tCurrent Loss : 3.753883\n",
            "Current Step : 20 / 1\tCurrent Loss : 3.768126\n",
            "Current Step : 30 / 1\tCurrent Loss : 3.780365\n",
            "Current Step : 40 / 1\tCurrent Loss : 3.561476\n",
            "Current Step : 50 / 1\tCurrent Loss : 3.573300\n",
            "Current Step : 60 / 1\tCurrent Loss : 3.584750\n",
            "Current Step : 70 / 1\tCurrent Loss : 3.573408\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIhLXar0Ta-Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc4f1e40-913a-48a1-f4e0-d5eac548b727"
      },
      "source": [
        "if(__name__==\"__main__\"):\n",
        "\n",
        "    root_dir = \"/gdrive/My Drive/ML/13w/\"\n",
        "    output_dir = os.path.join(root_dir, \"output\")\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "    config = {\"mode\": \"test\",\n",
        "              \"vocab_file\": os.path.join(root_dir, \"vocab.txt\"),\n",
        "              \"train_file\": os.path.join(root_dir, \"train.txt\"),\n",
        "              \"trained_model_name\":\"epoch_{}.pt\".format(10),\n",
        "              \"output_dir\":output_dir,\n",
        "              \"epoch\": 10,\n",
        "              \"learn_rate\":0.00005,\n",
        "              \"num_encoder_layers\": 6,\n",
        "              \"num_decoder_layers\": 6,\n",
        "              \"num_heads\": 4,\n",
        "              \"max_length\": 20,\n",
        "              \"batch_size\": 128,\n",
        "              \"embedding_size\": 256,\n",
        "              \"hidden_size\": 512,\n",
        "              \"vocab_size\": 4427\n",
        "            }\n",
        "\n",
        "    if(config[\"mode\"] == \"train\"):\n",
        "        train(config)\n",
        "    else:\n",
        "        test(config)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n",
            "<ipython-input-9-f81072fa4507>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(os.path.join(config[\"output_dir\"], config[\"trained_model_name\"])))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "문장을 입력하세요. (종료는 exit을 입력하세요.) : 입고 있는 상의 정보 알려주세요!\n",
            "저는아니이이이이아니다이\n",
            "문장을 입력하세요. (종료는 exit을 입력하세요.) : 옷 색깔이 참 이뻐요\n",
            "저는아니이이이이아니다이\n",
            "문장을 입력하세요. (종료는 exit을 입력하세요.) : 청바지가 잘 어울리네요\n",
            "저는아니이이이이이아니다\n",
            "문장을 입력하세요. (종료는 exit을 입력하세요.) : 니트가 따뜻해보여요\n",
            "저는아니이이이이아니다이\n",
            "문장을 입력하세요. (종료는 exit을 입력하세요.) : 베이지색 바지\n",
            "저는아니이이이이아니다이\n",
            "문장을 입력하세요. (종료는 exit을 입력하세요.) : 대학생을 위한 티셔츠 정보\n",
            "저는이이이아니다이이이\n",
            "문장을 입력하세요. (종료는 exit을 입력하세요.) : 검정색 자켓이 멋져\n",
            "저는아니이이이이아니다이\n",
            "문장을 입력하세요. (종료는 exit을 입력하세요.) : exit\n"
          ]
        }
      ]
    }
  ]
}