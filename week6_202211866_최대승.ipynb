{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 과제를 수행하며 피처를 두 가지 추가하였습니다."
      ],
      "metadata": {
        "id": "ToBXIJbSo5M9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. 기존 모델의 피처 8가지\n",
        "-  \"BOS\" : 시작 음절인지 여부\n",
        "-  \"EOS\" : 마지막 음절인지 여부\n",
        "-  \"WORD\" : 기준 음절\n",
        "-  \"IS_DIGIT\" : 기준 음절이 숫자인지 여부\n",
        "-  \"-1_WORD\" : 기준 음절의 왼쪽 첫번째 음절\n",
        "-  \"-2_WORD\" : 기준 음절의 왼쪽 두번째 음절\n",
        "-  \"+1_WORD\" : 기준 음절의 오른쪽 첫번째 음절\n",
        "-  \"+2_WORD\" : 기준 음절의 오른쪽 두번째 음절\n"
      ],
      "metadata": {
        "id": "eWPNGBCTiw8V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. 기존 모델의 Accuracy score\n",
        "- 0.8964135826020603"
      ],
      "metadata": {
        "id": "nRrWqLt2m4hB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. 기존 모델의 출력과 실제 정답 비교를 통해 알 수 있는 오차들\n",
        "\n",
        "### 3-1. 지시 관형사 오차 (ex. 하지만 이 전쟁-> 하지만이 전쟁, 이 암살행위-> 이암살행위)\n",
        " - 정답 문장 : 하지만 이 전쟁은 죽음을 통해 인류를 통합시켰다.\n",
        "\n",
        "- 출력 문장 : 하지만이 전쟁은 죽음을 통해 인류를 통합시켰다.\n",
        "\n",
        "- 정답 문장 : 이 암살행위는 국지적인 민족주의들과 세계적인 제국주의들이 충돌하는 분쟁지역에서 저질러졌다.\n",
        "- 출력 문장 : 이암 살행 위는 국지적인 민족주의 들과 세계적인 제국주의 들이 충돌하는 분쟁 지역에서 저질러졌다.\n",
        "\n",
        "### 3-2. 접미사 오차 (ex. 점진적인-> 점진 적인)\n",
        "- 정답 문장 : 오토만제국의 점진적인 해체는 민족주의의 독기를 발산하는 동시에 오스트리아, 헝가리와 독일, 영국, 프랑스의 탐욕을 자극했다.\n",
        "- 출력 문장 : 오토만 제국의 점진 적인 해체는 민족주의의 독기를 발산하는 동시에 오스트리아, 헝가리와 독일, 영국, 프랑스의 탐욕을 자극했다."
      ],
      "metadata": {
        "id": "1wUBUQjNlkks"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. 과제를 수행하며 새로 추가한 피처\n",
        "\n",
        "- \"demonstratives\": 지시 관형사\n",
        "- \"suffixes\": 접미사\n"
      ],
      "metadata": {
        "id": "onYCjo1akIot"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. 새로운 피처를 추가한 모델의 Accuracy score\n",
        "- 0.8969858832506676"
      ],
      "metadata": {
        "id": "z6te6QkZoELk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. 결론\n",
        "- 새로운 피처를 추가하고 Accuracy score이 0.0005723006486073 증가했다."
      ],
      "metadata": {
        "id": "XVXmz2vgoQ_o"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5o0lh-JLURY7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b9a7122-9b54-46cb-c49d-308e3c5a5400"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/gdrive\", force_remount=True)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwzrDnJYmV3Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd8c04cf-be8e-4cea-fc2f-c63d4461f3b6"
      },
      "source": [
        "!pip install sklearn-crfsuite"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sklearn-crfsuite\n",
            "  Downloading sklearn_crfsuite-0.5.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting python-crfsuite>=0.9.7 (from sklearn-crfsuite)\n",
            "  Downloading python_crfsuite-0.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite) (1.5.2)\n",
            "Requirement already satisfied: tabulate>=0.4.2 in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite) (0.9.0)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite) (4.66.5)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.0->sklearn-crfsuite) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.0->sklearn-crfsuite) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.0->sklearn-crfsuite) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.0->sklearn-crfsuite) (3.5.0)\n",
            "Downloading sklearn_crfsuite-0.5.0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading python_crfsuite-0.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-crfsuite, sklearn-crfsuite\n",
            "Successfully installed python-crfsuite-0.9.11 sklearn-crfsuite-0.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUf7YKTATa8G"
      },
      "source": [
        "<pre>\n",
        "<h2> 1. \"spacing_data.txt\"로 부터 데이터를 읽고 datas에 저장 </h2>\n",
        "  1.1 입력 데이터 형태\n",
        "    예시) 나 는 사 과 가 좋 아 \\t B I B I I B I\n",
        "    \n",
        "    \"나는 사과가 좋아\" 라는 문장이 있을 때, 공백을 기준으로 나눈 \"나는\", \"사과가\", \"좋아\"를 각각 어절이라고 함\n",
        "    각 어절의 시작음절을 \"B\"로 나머지를 \"I\"로 태깅하였고 문장과 라벨을 \\t으로 구분해놓은 상태\n",
        "\n",
        "  1.2 데이터 변환\n",
        "\n",
        "    입력 데이터를 읽고 탭을 기준으로 문장과 라벨을 분리\n",
        "    문장을 공백을 기준으로 나눈다\n",
        "      예시)\"나 는 사 과 가 좋 아\" -> [\"나\", \"는\", \"사\", \"과\", \"가\", \"좋\", \"아\"]\n",
        "    문장과 라벨을 튜플형태로 datas 리스트에 넣는다\n",
        "    datas = [ ( [\"나\", \"는\", \"사\", \"과\", \"가\", \"좋\", \"아\"], [\"B\", \"I\", \"B\", \"I\", \"I\", \"B\", \"I\"] ), ( ... ), ... ]\n",
        "    \n",
        "<h2> 2. 전체 데이터를 9:1 비율에 맞추어 학습, 평가 데이터로 나누기 </h2>\n",
        "  2.1 train_datas 리스트와 test_datas 리스트에 나누어 저장\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VJD-PF6dYfb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfeefb1a-41e6-4f1e-bdf2-ef95f85f92dd"
      },
      "source": [
        "import os\n",
        "import sklearn_crfsuite\n",
        "from sklearn_crfsuite import metrics\n",
        "\n",
        "\n",
        "# 파일 경로\n",
        "file_path = \"/gdrive/My Drive/ML/spacing_data.txt\"\n",
        "\n",
        "# \"spacing_data.txt\" 파일을 읽고 lines에 읽은 데이터를 저장\n",
        "with open(file_path, \"r\", encoding=\"utf8\") as inFile:\n",
        "    lines = inFile.readlines()\n",
        "\n",
        "# 데이터를 음절로 이루어진 문장과 정답 값으로 나누어 저장\n",
        "datas = []\n",
        "# 이곳을 채우세요.\n",
        "for line in lines:\n",
        "    # 문장과 라벨을 탭으로 구분하여 분리\n",
        "    sentence, labels = line.strip().split(\"\\t\")\n",
        "    # 문장을 공백으로 분리하여 음절 단위로 리스트화\n",
        "    sentence_eumjeols = sentence.split(\" \")\n",
        "    # 라벨을 공백으로 분리하여 리스트화\n",
        "    labels_list = labels.split(\" \")\n",
        "    # 음절 리스트와 라벨 리스트를 튜플로 datas에 추가\n",
        "    datas.append((sentence_eumjeols, labels_list))\n",
        "\n",
        "number_of_train_datas = int(len(datas)*0.9)\n",
        "\n",
        "train_datas = datas[:number_of_train_datas]\n",
        "test_datas = datas[number_of_train_datas:]\n",
        "\n",
        "print(\"train_datas 개수 : \" + str(len(train_datas)))\n",
        "print(\"test_datas 개수 : \" + str(len(test_datas)))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_datas 개수 : 900\n",
            "test_datas 개수 : 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoVhuFogkT36"
      },
      "source": [
        "<pre>\n",
        "<h2> 1. 문장의 각 음절을 crf 모델의 입력으로 사용 할 수 있도록 자질화 </h2>\n",
        "  \"BOS\" : 시작 음절인지 여부\n",
        "  \"EOS\" : 마지막 음절인지 여부\n",
        "  \"WORD\" : 기준 음절\n",
        "  \"IS_DIGIT\" : 기준 음절이 숫자인지 여부\n",
        "  \"-1_WORD\" : 기준 음절의 왼쪽 첫번째 음절\n",
        "  \"-2_WORD\" : 기준 음절의 왼쪽 두번째 음절\n",
        "  \"+1_WORD\" : 기준 음절의 오른쪽 첫번째 음절\n",
        "  \"+2_WORD\" : 기준 음절의 오른쪽 두번째 음절\n",
        "  \n",
        "  과제를 수행하면서 피처를 두 가지 새로 추가\n",
        "  \"demonstratives\": 지시 관형사\n",
        "  \"suffixes\": 접미사\n",
        "\n",
        "\n",
        "\n",
        "  1.1 예시) [\"나\", \"는\", \"사\", \"과\", \"가\", \"좋\", \"아\"]\n",
        "            ->\n",
        "            [ { \"BOS\":True, \"EOS\":False, \"WORD\":\"나\", \"IS_DIGIT\":False, \"+1_WORD\":\"는\", \"+2_WORD\":\"사\" },\n",
        "    { \"BOS\":False, \"EOS\":False, \"WORD\":\"는\", \"IS_DIGIT\":False, \"-1_WORD\":\"나\", \"+1_WORD\":\"사\", \"+2_WORD\":\"과\" },\n",
        "    { \"BOS\":False, \"EOS\":False, \"WORD\":\"사\", \"IS_DIGIT\":False, \"-2_WORD\":\"나\", \"-1_WORD\":\"는\", \"+1_WORD\":\"과\", \"+2_WORD\":\"가\" }, ... ]\n",
        "    \n",
        "    나 -> { \"BOS\":True, \"EOS\":False, \"WORD\":\"나\", \"IS_DIGIT\":False, \"+1_WORD\":\"는\", \"+2_WORD\":\"사\" }\n",
        "    는 -> { \"BOS\":False, \"EOS\":False, \"WORD\":\"는\", \"IS_DIGIT\":False, \"-1_WORD\":\"나\", \"+1_WORD\":\"사\", \"+2_WORD\":\"과\" }\n",
        "    사 -> { \"BOS\":False, \"EOS\":False, \"WORD\":\"사\", \"IS_DIGIT\":False, \"-2_WORD\":\"나\", \"-1_WORD\":\"는\", \"+1_WORD\":\"과\", \"+2_WORD\":\"가\" }\n",
        "    과 -> { \"BOS\":False, \"EOS\":False, \"WORD\":\"과\", \"IS_DIGIT\":False, \"-2_WORD\":\"는\", \"-1_WORD\":\"사\", \"+1_WORD\":\"가\", \"+2_WORD\":\"좋\" }\n",
        "    가 -> { \"BOS\":False, \"EOS\":False, \"WORD\":\"가\", \"IS_DIGIT\":False, \"-2_WORD\":\"사\", \"-1_WORD\":\"과\", \"+1_WORD\":\"좋\", \"+2_WORD\":\"아\" }\n",
        "    좋 -> { \"BOS\":False, \"EOS\":False, \"WORD\":\"좋\", \"IS_DIGIT\":False, \"-2_WORD\":\"과\", \"-1_WORD\":\"가\", \"+1_WORD\":\"아\" }\n",
        "    아 -> { \"BOS\":False, \"EOS\":True, \"WORD\":\"아\", \"IS_DIGIT\":False, \"-2_WORD\":\"가\", \"-1_WORD\":\"좋\" }\n",
        "<h2> 2. 자질화한 데이터와 해당 데이터의 라벨을 분리하여 각 리스트에 저장 </h2>\n",
        "  학습 데이터 -> train_x(자질화한 데이터), train_y(각 데이터의 정답 라벨)에 저장\n",
        "  평가 데이터 -> test_x(자질화한 데이터), test_y(각 데이터의 정답 라벨)에 저장\n",
        "  \n",
        "  2.1 예시)\n",
        "    train_x -> [\n",
        "    \n",
        "    [ { \"BOS\":True, \"EOS\":False, \"WORD\":\"나\", \"IS_DIGIT\":False, \"+1_WORD\":\"는\", \"+2_WORD\":\"사\" },\n",
        "    { \"BOS\":False, \"EOS\":False, \"WORD\":\"는\", \"IS_DIGIT\":False, \"-1_WORD\":\"나\", \"+1_WORD\":\"사\", \"+2_WORD\":\"과\" },\n",
        "    { \"BOS\":False, \"EOS\":False, \"WORD\":\"사\", \"IS_DIGIT\":False, \"-2_WORD\":\"나\", \"-1_WORD\":\"는\", \"+1_WORD\":\"과\", \"+2_WORD\":\"가\" }, ... ],\n",
        "    \n",
        "    [ ... ],\n",
        "    \n",
        "    ...\n",
        "    \n",
        "    ]\n",
        "    \n",
        "    train_y -> [\n",
        "    \n",
        "    [ \"B\", \"I\", \"B\", \"I\", \"I\", \"B\", \"I\" ],\n",
        "    \n",
        "    [ ... ],\n",
        "    \n",
        "    ...\n",
        "    \n",
        "    \n",
        "    ]\n",
        "\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 새로운 피처 (접미사, 지시 관형사)를 추가하여 성능개선 시도\n",
        "\n",
        "suffixes = ['적', '들', '함', '성']  # 접미사 리스트\n",
        "demonstratives = ['이', '그', '저', '이런', '그런', '저런'] # 지시 관형사\n",
        "\n",
        "\n",
        "def sent2feature(eumjeol_sequence):\n",
        "    features = []\n",
        "    sequence_length = len(eumjeol_sequence)\n",
        "\n",
        "    for index, eumjeol in enumerate(eumjeol_sequence):\n",
        "        # 지시 관형사 여부 확인\n",
        "        is_demonstrative = eumjeol in demonstratives\n",
        "\n",
        "\n",
        "        # 기본 피처\n",
        "        feature = {\n",
        "            \"BOS\": index == 0,\n",
        "            \"EOS\": index == sequence_length - 1,\n",
        "            \"WORD\": eumjeol if eumjeol is not None else \"\",  # None 방지\n",
        "            \"IS_DIGIT\": eumjeol.isdigit() if eumjeol else False,\n",
        "            \"-1_WORD\": eumjeol_sequence[index-1] if index > 0 else \"BOS\",\n",
        "            \"-2_WORD\": eumjeol_sequence[index-2] if index > 1 else \"BOS\",\n",
        "            \"+1_WORD\": eumjeol_sequence[index+1] if index < sequence_length - 1 else \"EOS\",\n",
        "            \"+2_WORD\": eumjeol_sequence[index+2] if index < sequence_length - 2 else \"EOS\",\n",
        "\n",
        "            # 새로운 피처 추가\n",
        "            \"SUFFIX\": any(eumjeol.endswith(suffix) for suffix in suffixes),  # 접미사 여부\n",
        "            \"IS_DEMONSTRATIVE\": is_demonstrative  # 지시 관형사 여부\n",
        "\n",
        "        }\n",
        "\n",
        "        features.append(feature)\n",
        "\n",
        "    return features\n",
        "\n",
        "train_x, train_y = [], []\n",
        "for eumjeol_sequence, label in train_datas:\n",
        "    train_x.append(sent2feature(eumjeol_sequence))\n",
        "    train_y.append(label)\n",
        "\n",
        "test_x, test_y = [], []\n",
        "for eumjeol_sequence, label in test_datas:\n",
        "    test_x.append(sent2feature(eumjeol_sequence))\n",
        "    test_y.append(label)"
      ],
      "metadata": {
        "id": "t51IUNHuRNIj"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYwRX9Vdn5-D"
      },
      "source": [
        "<h2> 1. train_x, train_y를 이용하여 crf 모델 학습 </h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odbrhxSKStT-"
      },
      "source": [
        "#crf = sklearn_crfsuite.CRF(\n",
        "#        algorithm='lbfgs',\n",
        "#        c1=0.1,\n",
        "#        c2=0.1,\n",
        "#        max_iterations=100,\n",
        "#        all_possible_transitions=True\n",
        "#    )\n",
        "crf = sklearn_crfsuite.CRF()\n",
        "try:\n",
        "    crf.fit(train_x, train_y)\n",
        "except AttributeError:\n",
        "    pass"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07BbK76nuZVK"
      },
      "source": [
        "<pre>\n",
        "<h2> 1. 학습한 모델을 test_x 데이터를 사용하여 평가 </h2>\n",
        "<h2> 2. 성능 측정 </h2>\n",
        "  2.1 metrics.flat_accuracy_score(x, y) 함수를 이용하여 성능 측정\n",
        "    metrics.flat_accuracy_score(x, y)\n",
        "  args\n",
        "    x : 실제 정답 라벨이 있는 리스트\n",
        "    y : 모델의 출력 라벨이 있는 리스트\n",
        "  return :\n",
        "    accuract 성능\n",
        "  \n",
        "<h2> 3. 모델의 출력 값과 정답 값을 이용하여 음절만으로 구성된 완전한 문장으로 변형 </h2>\n",
        "  3.1 test_datas, pred_y 예시\n",
        "    test_datas = [\n",
        "    ( [\"나\", \"는\", \"사\", \"과\", \"가\", \"좋\", \"아\"], [\"B\", \"I\", \"B\", \"I\", \"I\", \"B\", \"I\"] ),\n",
        "    \n",
        "    ( ... ),\n",
        "    \n",
        "    ...\n",
        "    \n",
        "    ]\n",
        "    \n",
        "    pred_y = [\n",
        "    \n",
        "    [\"B\", \"B\", \"B\", \"I\", \"I\", \"I\", \"I\"],\n",
        "    \n",
        "    [ ... ],\n",
        "    \n",
        "    ...\n",
        "    \n",
        "    ]\n",
        "    \n",
        "    위의 문장을 기준으로한 변형 예시\n",
        "    \n",
        "    \"나\", \"는\", \"사\", \"과\", \"가\", \"좋\", \"아\" -> 나는 사과가 좋아 (정답 기준으로 변형)\n",
        "    \"나\", \"는\", \"사\", \"과\", \"가\", \"좋\", \"아\" -> 나 는 사과가좋아 (모델 출력 기준으로 변형)\n",
        "  \n",
        "  3.2 최종 출력 예시\n",
        "  \n",
        "    정답 문장 : 1914- 18년의 전쟁은 인류를 통합시킨 최초의 공통분모였다.\n",
        "    출력 문장 : 19 14- 18년의 전쟁은 인류를 통합시킨 최초의 공통 분모였다.\n",
        "\n",
        "    정답 문장 : 하지만 이 전쟁은 죽음을 통해 인류를 통합시켰다.\n",
        "    출력 문장 : 하지만이 전쟁은 죽음을 통해 인류를 통합시켰다.\n",
        "\n",
        "    정답 문장 : 사라예보에서 한 세르비아인이 쏜 총 한발이 합스부르크가의 계승자를 죽였다.\n",
        "    출력 문장 : 사라 예보에서 한세르비아인이 쏜총한 발이 합스부르크가의 계승자를 죽였다.\n",
        "    \n",
        "    ...\n",
        "  \n",
        "  \n",
        "</pre>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgIPGK--SzmA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b040331-89fd-4e2b-cc5e-139584dd285f"
      },
      "source": [
        "def show_predict_result(test_datas, predict):\n",
        "  for index_1 in range(len(test_datas)):\n",
        "      eumjeol_sequence, correct_labels = test_datas[index_1]\n",
        "      predict_labels = predict[index_1]\n",
        "\n",
        "      correct_sentence, predict_sentence = \"\", \"\"\n",
        "      for index_2 in range(len(eumjeol_sequence)):\n",
        "          if(index_2 == 0):\n",
        "              correct_sentence += eumjeol_sequence[index_2]\n",
        "              predict_sentence += eumjeol_sequence[index_2]\n",
        "              continue\n",
        "\n",
        "          if(correct_labels[index_2] == \"B\"):\n",
        "              correct_sentence += \" \"\n",
        "          correct_sentence += eumjeol_sequence[index_2]\n",
        "\n",
        "          if (predict_labels[index_2] == \"B\"):\n",
        "              predict_sentence += \" \"\n",
        "          predict_sentence += eumjeol_sequence[index_2]\n",
        "\n",
        "      print(\"정답 문장 : \" + correct_sentence)\n",
        "      print(\"출력 문장 : \" + predict_sentence)\n",
        "      print()\n",
        "\n",
        "predict = crf.predict(test_x)\n",
        "\n",
        "print(\"Accuracy score : \" + str(metrics.flat_accuracy_score(test_y, predict)))\n",
        "print()\n",
        "\n",
        "print(\"10개의 데이터에 대한 모델 출력과 실제 정답 비교\")\n",
        "print()\n",
        "\n",
        "show_predict_result(test_datas[:10], predict[:10])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score : 0.8969858832506676\n",
            "\n",
            "10개의 데이터에 대한 모델 출력과 실제 정답 비교\n",
            "\n",
            "정답 문장 : 1914- 18년의 전쟁은 인류를 통합시킨 최초의 공통분모였다.\n",
            "출력 문장 : 1914- 18년의 전쟁은 인류를 통합시킨 최초의 공통분 모였다.\n",
            "\n",
            "정답 문장 : 하지만 이 전쟁은 죽음을 통해 인류를 통합시켰다.\n",
            "출력 문장 : 하지만이 전쟁은 죽음을 통해 인류를 통합시켰다.\n",
            "\n",
            "정답 문장 : 사라예보에서 한 세르비아인이 쏜 총 한발이 합스부르크가의 계승자를 죽였다.\n",
            "출력 문장 : 사라 예보에서 한 세르 비아인이 쏜총한 발이 합스부르크가의 계승 자를 죽였다.\n",
            "\n",
            "정답 문장 : 이 암살행위는 국지적인 민족주의들과 세계적인 제국주의들이 충돌하는 분쟁지역에서 저질러졌다.\n",
            "출력 문장 : 이암 살행 위는 국지적인 민족주의 들과 세계적인 제국주의 들이 충돌하는 분쟁 지역에서 저질러졌다.\n",
            "\n",
            "정답 문장 : 오토만제국의 점진적인 해체는 민족주의의 독기를 발산하는 동시에 오스트리아, 헝가리와 독일, 영국, 프랑스의 탐욕을 자극했다.\n",
            "출력 문장 : 오토만 제국의 점진 적인 해체는 민족주의의 독기를 발산하는 동시에 오스트리아, 헝가리와 독일, 영국, 프랑스의 탐욕을 자극했다.\n",
            "\n",
            "정답 문장 : 이렇게 해서 발칸 반도의 한 외진 장소에서 벌어진 국지적인 테러 행위는 일련의 긴박한 반응을 불러 일으키면서 전 유럽에 영향을 미쳤을 뿐만 아니라 이번에는 아시아와 아프리카 식민지들, 일본, 그리고 이어서 미국과 멕시코까지 끌어들였다.\n",
            "출력 문장 : 이렇게 해서 발칸 반도의 한외진 장소에서 벌어 진국지적인 테러행 위는 일련의 긴박한 반응을 불러일으키면서 전유럽에 영향을 미쳤을 뿐만 아니라이 번에는 아시아와 아프리카 식민지들, 일본, 그리고 이어서 미국과 멕시코까지 끌어들였다.\n",
            "\n",
            "정답 문장 : 전쟁의 물결이 지구상의 모든 대양으로 밀려드는 동안 캐나다인들과 미국인들, 오스트레일리아인들, 세네갈인들, 알제리인들, 모로코인들, 안남(安南)인들은 연합군 깃발을 휘날리며 유럽전선에서 싸웠다.\n",
            "출력 문장 : 전쟁의 물결이 지구상의 모든 대양으로 밀려드는 동안 캐나 다인들과 미국인들, 오스트레 일리 아인들, 세네 갈인들, 알 제리인들, 모로 코인들, 안 남(安南)인들은 연합군 깃발을 휘날리며 유럽 전선에서 싸웠다.\n",
            "\n",
            "정답 문장 : 앞서 살펴본 것처럼, 세계대전의 원인이 된 것은 대립관계에 있던 유럽 제국주의의 구심적 회귀였다.\n",
            "출력 문장 : 앞서 살펴본 것처럼, 세계 대전의 원인이된 것은 대립 관계에 있던 유럽 제국주의 의구심적회귀였다.\n",
            "\n",
            "정답 문장 : 그리고 세계대전을 촉발시킨 것은 주요 제국주의들과 소수 민족주의들 간의 상호작용이었다.\n",
            "출력 문장 : 그리고 세계 대전을 촉발시킨 것은 주요 제국주의 들과 소수 민족주의 들간의 상호 작용이었다.\n",
            "\n",
            "정답 문장 : 또한 세계대전의 빌미를 제공한 것은 격화된 민족주의들이었다.\n",
            "출력 문장 : 또한 세계 대전의 빌미를 제공한 것은 격화된 민족주의 들이었다.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}